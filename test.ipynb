{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset.FaceLandmarksDataset import FaceLandmarksDataset\n",
    "from src.model.FaceLandmarksModel import FacialLandmarksModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo model đã train sẵn\n",
    "path = '' # kh up được model lên github nên đẻ path rỗng up sau :v\n",
    "model = FacialLandmarksModel.load_from_checkpoint(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hàm vẽ loss sau khi train trên toàn bộ tập dữ liệu \n",
    "def plot_loss(model):\n",
    "    loss_values = [loss.cpu().item() for loss in model.loss_value] # Chuyển loss_value sang CPU nếu nó đang ở trên GPU\n",
    "    plt.plot(loss_values, label='Validation Loss')\n",
    "    plt.title('Loss per Validation Step')\n",
    "    plt.xlabel('Validation Step')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect trên một ảnh ngẫu nhiên thuộc tập Test\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "model.eval() \n",
    "dataset = FaceLandmarksDataset('/kaggle/input/ibug-300w/ibug_300W_large_face_landmark_dataset/labels_ibug_300W_test.xml')\n",
    "index =  104 \n",
    "image_path = dataset.image_filenames[index]\n",
    "\n",
    "# Đọc ảnh và xử lí sao cho khớp với ảnh đầu vào model \n",
    "image = cv2.imread(image_path)\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "bbox = dataset.crops[index]\n",
    "landmarks = dataset.landmarks[index]\n",
    "x1 = int(bbox['left'])\n",
    "y1 = int(bbox['top'])\n",
    "x2 = int(bbox['left']) + int(bbox['width'])\n",
    "y2 = int(bbox['top']) + int(bbox['height'])\n",
    "\n",
    "cropped_image = image_gray[y1:y2, x1:x2]\n",
    "resized_image = cv2.resize(cropped_image, (224, 224))\n",
    "input_image = torch.tensor(resized_image, dtype=torch.float32).unsqueeze(0).unsqueeze(0) / 255.0  # Thêm batch size và kênh\n",
    "\n",
    "# Detect với model \n",
    "with torch.no_grad():\n",
    "    predicted_landmarks = model(input_image)\n",
    "\n",
    "\n",
    "predicted_landmarks = predicted_landmarks.view(-1, 2).numpy()\n",
    "scale_x = cropped_image.shape[1] / 224.0\n",
    "scale_y = cropped_image.shape[0] / 224.0\n",
    "predicted_landmarks[:, 0] *= scale_x\n",
    "predicted_landmarks[:, 1] *= scale_y\n",
    "\n",
    "\n",
    "for (x, y) in predicted_landmarks:\n",
    "    cv2.circle(cropped_image, (int(x), int(y)), 2, (255, 0, 0), -1)\n",
    "\n",
    "plt.imshow(cropped_image, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "\n",
    "model.eval() \n",
    "dataset = FaceLandmarksDataset('/kaggle/input/ibug-300w/ibug_300W_large_face_landmark_dataset/labels_ibug_300W_test.xml')\n",
    "\n",
    "# Lưu trữ MES cho từng ảnh \n",
    "mse_per_image_list = []\n",
    "sum_mse = 0 \n",
    "# Vòng lặp qua tập test để dự đoán và tính MSE\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(dataset)):\n",
    "        # Lấy từng ảnh và nhãn từ test_dataset\n",
    "        image, true_landmarks = dataset[idx]  # Lấy ảnh và nhãn\n",
    "        image = image.unsqueeze(0)  # Thêm chiều batch vào ảnh\n",
    "\n",
    "        predicted_landmarks = model(image)  # Dự đoán landmarks\n",
    "\n",
    "        # Tính MSE cho ảnh hiện tại\n",
    "        mse = F.mse_loss(predicted_landmarks, true_landmarks.unsqueeze(0), reduction='mean')  # Tính MSE cho từng ảnh\n",
    "        sum_mse += mse \n",
    "        mse_per_image_list.append(mse.item())  # Thêm MSE vào danh sách\n",
    "\n",
    "# In MSE trung bình trên tập dataset\n",
    "print(mse/len(dataset))\n",
    "# In MSE cho từng ảnh\n",
    "for idx, mse in enumerate(mse_per_image_list):\n",
    "    print(f'Ảnh {idx + 1}: MSE = {mse}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
